### ðŸ”¹ Basic Kafka Interview Questions

1. What is Apache Kafka?
- Apache Kafka is a distributed event streaming platform used to build real-time data pipelines and streaming applications. 
- It is designed to handle high-throughput, low-latency, fault-tolerant data transmission across distributed systems.
- Apache Kafka is like a messaging system where different applications can send (produce) and receive (consume) data (messages) in real-time â€” much like a publish-subscribe system.

Core Features
1.High throughput â€“ Handles millions of messages per second.
2.Scalability â€“ Horizontally scalable by adding brokers.
3.Durability â€“ Data is persisted to disk.
4.Fault tolerance â€“ Replication across brokers ensures availability.
5.Real-time processing â€“ Supports stream processing via Kafka Streams.

Key Components
1.Producer â€“ Sends (publishes) messages to Kafka topics.
2.Consumer â€“ Reads messages from Kafka topics.
3.Topic â€“ A logical channel to which producers send and consumers read messages.
4.Broker â€“ A Kafka server that stores and manages messages.
5.Partition â€“ A topic is divided into partitions for scalability and parallelism.
6.Zookeeper â€“ Coordinates the Kafka brokers (metadata, leader election). (Optional in newer versions with KRaft mode)

Typical Use Cases
1.Real-time analytics and monitoring (e.g., website activity tracking)
2.Log aggregation (e.g., centralized log systems)
3.Event sourcing and CQRS
4.Messaging backbone between microservices
5.Stream processing pipelines (via Kafka Streams or Apache Flink)

2. What are the main components of Kafka?

1. Producer
* Sends (publishes) data (messages/events) to Kafka topics.
* Pushes data to a specific topic.
* Can choose the partition based on a key (for ordering) or let Kafka decide.
* Can be asynchronous or synchronous.

2. Consumer
* Reads data from Kafka topics.
* Works in consumer groups to enable parallel processing.
* Each partition is read by only one consumer in a group (load balancing).
* Tracks its position using offsets.

3. Topic
* A named stream of records/messages.
* Data is categorized and stored in topics.
* Topics are divided into partitions for scalability and parallelism.

4. Partition
* Each topic is split into one or more partitions.
* Messages within a partition are ordered.
* Allows Kafka to scale horizontally across brokers.
* Partitions are the unit of parallelism in Kafka.

5. Broker
* A Kafka server that stores data and serves clients.
* Each broker handles multiple topic-partitions.
* A Kafka cluster consists of multiple brokers.
* One broker acts as a leader for a partition; others are replicas.

6. Zookeeper (Deprecated in newer versions, replaced by KRaft mode)
* Used for cluster coordination, configuration, and leader election.
* Manages metadata and broker health.
* In Kafka 2.8+ and later, KRaft mode (Kafka Raft) removes dependency on Zookeeper.

7. Consumer Group
* A group of consumers working together to consume messages from a topic.
* Ensures scalable and fault-tolerant consumption.
* Each partition is assigned to only one consumer within the group.

8. Leader and Follower (Replication)
* Each partition has one leader and multiple followers.
* The leader handles all reads and writes.
* Followers replicate the data for high availability.


3. What is a Kafka topic and partition?
A Kafka topic is like a category or feed name to which records (messages) are sent by producers and from which they are read by consumers.
* Think of it as a channel where messages are published and subscribed.
* You can have multiple producers and multiple consumers for a single topic.
Example: A topic named `"user-signups"` could store all new user registration events.

What is a Partition?
A partition is a sub-division of a topic. Each topic can be split into multiple partitions to allow parallelism and scalability.

Each partition:
* Is an ordered sequence of messages.
* Stores messages with an offset (unique ID).
* Is stored on a Kafka broker.
* Has one leader (for read/write) and zero or more replicas (for fault tolerance).

Messages within a partition are always in the same order they were written.
Example:
Suppose you have a topic:
Topic: orders
Partitions: 3 (P0, P1, P2)
Kafka will distribute incoming messages across the 3 partitions. For example:

| Message | Partition |
| ------- | --------- |
| Order1  | P0        |
| Order2  | P1        |
| Order3  | P2        |
| Order4  | P0        |

Why Use Partitions?
* Scalability: Allows Kafka to distribute load across multiple brokers.
* Parallelism: Multiple consumers can read in parallel.
* Performance: Better throughput for both producers and consumers.

Summary Table:

| Concept   | Description                           |
| --------- | ------------------------------------- |
| Topic     | Logical stream of messages            |
| Partition | Physical storage unit within a topic  |
| Offset    | Unique ID of a message in a partition |
| Broker    | Kafka server storing topic partitions |


4. What is the role of Zookeeper in Kafka?
Role of Zookeeper in Apache Kafka (Traditional Kafka Architecture)
-Apache Kafka traditionally uses Apache Zookeeper to manage and coordinate the Kafka cluster.
-Zookeeper helps maintain cluster metadata, broker status, and configuration data.


Key Roles of Zookeeper in Kafka

1. Broker Registration and Discovery
   * Keeps track of all Kafka brokers in the cluster.
   * When a new broker starts, it registers itself with Zookeeper.

2. Leader Election
   * Helps elect a leader broker for each topic partition.
   * Ensures high availability by choosing another leader if the current one fails.

3. Configuration Management
   * Stores important configuration data (like ACLs, quotas, etc.).
   * Allows brokers and clients to fetch updated settings.

4. Cluster State Management
   * Tracks which brokers are alive and which are down.
   * Acts as the source of truth for Kafka cluster health.

5. Controller Election
   * Kafka has a controller node responsible for managing partition leaders and replicas.
   * Zookeeper helps elect and monitor this controller.

6. Topic Metadata and Quorum Management
   * Zookeeper maintains metadata like which partitions belong to which broker.
   * Assists in maintaining synchronization between brokers.


Architecture Diagram (Simplified):

Kafka Cluster
 â”œâ”€â”€ Broker 1
 â”œâ”€â”€ Broker 2
 â””â”€â”€ Broker 3
      â†‘
     [ Zookeeper ]
       (Manages brokers, leader election, configs)


Kafka without Zookeeper)

* Since Kafka 2.8, Kafka has introduced KRaft mode (Kafka Raft Metadata mode), which allows running Kafka without Zookeeper.
* Kafka now manages metadata internally using the Raft consensus algorithm.

Summary:

| Function                  | Role of Zookeeper                        |
| ------------------------- | ---------------------------------------- |
| Broker Management         | Registers, tracks, and discovers brokers |
| Leader Election           | Picks partition and controller leaders   |
| Configuration Storage     | Centralized config repository            |
| Cluster Health Monitoring | Tracks broker and controller status      |



5. What is a Kafka producer and consumer?
What is a Kafka Producer?
A Kafka Producer is a client application that sends (publishes) data to Kafka topics.

Key Points:
* Sends records (key-value pairs) to Kafka topics.
* Can write to a specific partition using a key, or let Kafka assign one.
* Supports asynchronous (non-blocking) and synchronous (blocking) sends.
* Can configure acknowledgment levels for reliability:

  * `acks=0`: No acknowledgment.
  * `acks=1`: Leader acknowledgment.
  * `acks=all`: All in-sync replicas must acknowledge.

Example: A web app sends user activity logs to a Kafka topic using a producer.


What is a Kafka Consumer?

A Kafka Consumer is a client application that reads (subscribes to) data from Kafka topics.

Key Points:

* Reads messages from one or more topics.
* Belongs to a consumer group for load balancing.
* Each partition is read by only one consumer per group.
* Tracks read progress using offsets (can auto-commit or manually commit).

Example: A service that reads user activity logs from Kafka to analyze behavior.

Flow Summary:
[ Producer ] â†’ sends â†’ [ Kafka Topic (with partitions) ] â†’ read by â†’ [ Consumer ]

Real-World Example:
* Producer: A payment service sends transaction data.
* Kafka: Stores the transactions in a `payments` topic.
* Consumer: A fraud detection service reads transactions in real time.

Summary Table:

| Feature    | Kafka Producer           | Kafka Consumer                |
| ---------- | ------------------------ | ----------------------------- |
| Role       | Publishes data to Kafka  | Reads data from Kafka         |
| Sends to   | Topics (and partitions)  | Subscribes to topics          |
| Common Use | Logging, metrics, events | Analytics, alerts, processing |
| Offset     | Not applicable           | Tracks position in the topic  |



6. How does Kafka ensure message durability?
7. What is the difference between Kafka and traditional messaging systems like RabbitMQ or ActiveMQ?
8. How do Kafka consumers read data?
9. What is a consumer group in Kafka?
10. How does Kafka handle message retention?

---

### ðŸ”¹ Intermediate Kafka Interview Questions

1. What happens if a Kafka broker goes down?
2. What is ISR (In-Sync Replicas)?
3. How does Kafka provide fault tolerance?
4. Explain producer acknowledgment levels (acks=0, 1, all).
5. How can you achieve exactly-once message delivery in Kafka?
6. What is Kafka offset? How is it managed?
7. Difference between Kafka at-most-once, at-least-once, and exactly-once delivery semantics?
8. What is log compaction in Kafka?
9. How do Kafka partitions help with scalability?
10. How can you monitor Kafka? What tools are available?

---

### ðŸ”¹ Advanced Kafka Interview Questions

1. What is Kafka Streams? How is it different from Kafka Consumer API?
2. How does Kafka handle backpressure?
3. What are idempotent producers in Kafka?
4. What is the role of Kafka Connect?
5. How do you secure a Kafka cluster?

   * SSL, SASL, ACLs
6. What is the use of Kafka Schema Registry?
7. How does Kafka guarantee order of messages?
8. How do you implement transactional messaging in Kafka?
9. How do you perform Kafka cluster rebalancing?
10. Describe Kafka internal storage format.

---

### ðŸ”¹ Scenario-Based Kafka Questions

1. How would you design a Kafka-based system to process millions of messages per second?
2. What would you do if consumers are falling behind the producer rate?
3. How to handle message replay in Kafka?
4. Your Kafka consumer keeps getting duplicate messages â€” how would you debug and fix it?
5. Describe a time you handled a Kafka cluster upgrade.
